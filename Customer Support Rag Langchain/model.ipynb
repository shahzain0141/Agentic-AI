{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "110ebd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded documents to running Docker Qdrant.\n",
      "Answer: I understand that you're having trouble setting up a different delivery address, and I'm here to help. Please follow these steps to address this issue:\n",
      "\n",
      "1. Log in to your account.\n",
      "2. Go to the 'My Account' or 'Profile' section.\n",
      "3. Look for the 'Shipping Addresses' or similar option.\n",
      "4. Choose 'Add a New Address' or 'Edit Shipping Addresses'.\n",
      "5. Enter the details of the new delivery address in the provided fields.\n",
      "6. Review the information for accuracy and save the changes.\n",
      "\n",
      "If you encounter any difficulties or have further questions, please feel free to reach out to me. I'm here to provide assistance and support.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def load_txt_as_documents(txt_file):\n",
    "    with open(txt_file, 'r', encoding='utf-8') as f:\n",
    "        raw_text = f.read()\n",
    "    return raw_text\n",
    "\n",
    "\n",
    "raw_text = load_txt_as_documents(r\"C:\\Users\\FINE LAPTOP\\Desktop\\Langchain\\langgraph\\rag_service.txt\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "documents = [Document(page_content=chunk) for chunk in texts]\n",
    "\n",
    "\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "qdrant_client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "qdrant_client.recreate_collection(\n",
    "    collection_name=\"rag_txt_collection\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "\n",
    "db = Qdrant(\n",
    "    client=qdrant_client,\n",
    "    collection_name=\"rag_txt_collection\",\n",
    "    embeddings=embedding_function\n",
    ")\n",
    "\n",
    "\n",
    "db.add_documents(documents)\n",
    "\n",
    "print(\"Uploaded documents to running Docker Qdrant.\")\n",
    "\n",
    "\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    context: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "def retrieve(state: GraphState):\n",
    "    query = state[\"question\"]\n",
    "    retriever = db.as_retriever()\n",
    "    docs = retriever.invoke(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    return {\"question\": query, \"context\": context}\n",
    "\n",
    "\n",
    "def generate(state: GraphState):\n",
    "    prompt = f\"\"\"Answer the question using this context:\\n\\n{state['context']}\\n\\nQuestion: {state['question']}\"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\n",
    "        \"question\": state[\"question\"],\n",
    "        \"context\": state[\"context\"],\n",
    "        \"answer\": response.content\n",
    "    }\n",
    "\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "graph.add_node(\"retrieve\", RunnableLambda(retrieve))\n",
    "graph.add_node(\"generate\", RunnableLambda(generate))\n",
    "graph.set_entry_point(\"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"generate\")\n",
    "graph.add_edge(\"generate\", END)\n",
    "app = graph.compile()\n",
    "\n",
    "\n",
    "inputs = {\"question\": \"I have an issue setting a different delivery address up\"}\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "print(result['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387c9bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
