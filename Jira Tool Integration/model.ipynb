{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f6ce35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shahzain -1.pdf (1Pb987kphhul9ZeXtGwzRIzv4GyYfyJWl) - application/pdf\n",
      "Innovaxel | Take Home Assignment | Backend - Summer Intern (1BoQA7nEsrK6ah5fNRG47BXC6W3ZnG_l0sGz2WnxqUDE) - application/vnd.google-apps.document\n",
      "Shah cv.pdf (1Cq7MriFdOQA98wbDOvXRPuYnsYx4G0zE) - application/pdf\n",
      "Shah cv.pdf (1ueJS99efnAtlL5XStBSZJuS3LKmgw3q2) - application/pdf\n",
      "Shah cv.pdf (1p-xCIVbxye3DITf4V5vbylCjCpGba9RR) - application/pdf\n",
      "Shah cv.pdf (1p3ghmdyBLXzrh5viqrDkd6C0IBApMWd8) - application/pdf\n",
      "Shah Zain final1 (2).pdf (14eOI0HkDgotroXhYPfyC6nPzsSXE-zO5) - application/pdf\n",
      "Shah Zain (1).pdf (1uR_nrad4DyuG9cu9DmmmUYxa1wkgk5YL) - application/pdf\n",
      "Shah Zain (1).pdf (1WH1A6YxGvwD_ZXg3iztvpRev-s16E0D-) - application/pdf\n",
      "2D3MF.pdf (10gjCXD-Bkpe5J_U6OYoDl57_HDTo6K4Q) - application/pdf\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "import os, pickle\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "creds = None\n",
    "\n",
    "if os.path.exists('token.pkl'):\n",
    "    with open('token.pkl', 'rb') as token:\n",
    "        creds = pickle.load(token)\n",
    "\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(r\"C:\\Users\\FINE LAPTOP\\Desktop\\Langchain\\langgraph\\client_secret_360782607957-dtr7rusrjsi5r558fiv6g60qg9930hmn.apps.googleusercontent.com.json\", SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    with open('token.pkl', 'wb') as token:\n",
    "        pickle.dump(creds, token)\n",
    "\n",
    "\n",
    "service = build('drive', 'v3', credentials=creds)\n",
    "results = service.files().list(\n",
    "    q=\"mimeType='application/pdf' or mimeType='application/vnd.google-apps.document'\",\n",
    "    pageSize=10,\n",
    "    fields=\"files(id, name, mimeType)\"\n",
    ").execute()\n",
    "\n",
    "files = results.get('files', [])\n",
    "for f in files:\n",
    "    print(f\"{f['name']} ({f['id']}) - {f['mimeType']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93922a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "file_id = \"1WigYzL1C9d-m47oA-1_w5ceSRJ5GSUGU\" \n",
    "request = service.files().get_media(fileId=file_id)\n",
    "\n",
    "fh = io.BytesIO()\n",
    "downloader = MediaIoBaseDownload(fh, request)\n",
    "done = False\n",
    "while not done:\n",
    "    status, done = downloader.next_chunk()\n",
    "\n",
    "with open(\"document.txt\", \"wb\") as f:\n",
    "    f.write(fh.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "746250b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded documents to running Docker Qdrant.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def load_txt_as_documents(txt_file):\n",
    "    with open(txt_file, 'r', encoding='utf-8') as f:\n",
    "        raw_text = f.read()\n",
    "    return raw_text\n",
    "\n",
    "\n",
    "raw_text = load_txt_as_documents(r\"C:\\Users\\FINE LAPTOP\\Desktop\\Langchain\\langgraph\\document.txt\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "documents = [Document(page_content=chunk) for chunk in texts]\n",
    "\n",
    "\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "qdrant_client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "qdrant_client.recreate_collection(\n",
    "    collection_name=\"rag_txt_collection\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "\n",
    "db = Qdrant(\n",
    "    client=qdrant_client,\n",
    "    collection_name=\"rag_txt_collection\",\n",
    "    embeddings=embedding_function\n",
    ")\n",
    "\n",
    "\n",
    "db.add_documents(documents)\n",
    "\n",
    "print(\"Uploaded documents to running Docker Qdrant.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8674d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    context: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "def retrieve(state: GraphState):\n",
    "    query = state[\"question\"]\n",
    "    retriever = db.as_retriever()\n",
    "    docs = retriever.invoke(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    return {\"question\": query, \"context\": context}\n",
    "\n",
    "\n",
    "def generate(state: GraphState):\n",
    "    prompt = f\"\"\"Answer the question using this context:\\n\\n{state['context']}\\n\\nQuestion: {state['question']}\"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\n",
    "        \"question\": state[\"question\"],\n",
    "        \"context\": state[\"context\"],\n",
    "        \"answer\": response.content\n",
    "    }\n",
    "\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "graph.add_node(\"retrieve\", RunnableLambda(retrieve))\n",
    "graph.add_node(\"generate\", RunnableLambda(generate))\n",
    "graph.set_entry_point(\"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"generate\")\n",
    "graph.add_edge(\"generate\", END)\n",
    "app = graph.compile()\n",
    "\n",
    "\n",
    "inputs = {\"question\": \"I have an issue setting a different delivery address up\"}\n",
    "result = app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf266a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì User Question:\n",
      "--------------------------------------------------------------------------------\n",
      "I have an issue setting a different delivery address up\n",
      "--------------------------------------------------------------------------------\n",
      "üì¨ AI Response:\n",
      "--------------------------------------------------------------------------------\n",
      "Answer: It seems like you're encountering difficulties setting up a different delivery address, and I'm here to assist you with that. To address this issue, please follow these steps:\n",
      "\n",
      "1. Log in to your account.  \n",
      "2. Go to the 'Delivery Addresses' or 'Shipping Settings' section.  \n",
      "3. Look for the option to 'Add New Address' or 'Edit Address'.  \n",
      "4. Enter the details of your new delivery address accurately.  \n",
      "5. Save the changes and ensure that the new address is set up correctly.  \n",
      "\n",
      "If you need further assistance or encounter any obstacles during this process, please don't hesitate to reach out to me. I'm here to help resolve any issues you may have with setting up your different delivery address.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_answer(question: str, answer: str):\n",
    "    print(\"‚ùì User Question:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(question.strip())\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    print(\"üì¨ AI Response:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    lines = answer.strip().split(\"\\n\")\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith((\"1.\", \"2.\", \"3.\", \"4.\", \"5.\", \"6.\", \"7.\", \"8.\", \"9.\")):\n",
    "            print(f\"{line}  \") \n",
    "        elif line == \"\":\n",
    "            print()\n",
    "        else:\n",
    "            print(line)\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "pretty_print_answer(result[\"question\"], result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ada23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
